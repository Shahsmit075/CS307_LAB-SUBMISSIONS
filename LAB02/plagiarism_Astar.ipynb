{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wMsRQhH7nVzT"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egb-LezTvdWU",
        "outputId": "d08086ce-a749-4eba-ee1b-3d6d94a5ff2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt', quiet=True)\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yUKeiC5dwFXf"
      },
      "outputs": [],
      "source": [
        "# Text Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    sentences = sent_tokenize(text)\n",
        "    cleaned_sentences = [remove_punctuation(sentence) for sentence in sentences]\n",
        "    return cleaned_sentences\n",
        "\n",
        "def remove_punctuation(sentence):\n",
        "    return sentence.translate(str.maketrans(\"\\n\", \" \", string.punctuation))\n",
        "\n",
        "def read_file(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        content = file.read()\n",
        "    return content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xonu4f-9wFpL"
      },
      "outputs": [],
      "source": [
        "# State Representation and A* Search\n",
        "class Node:\n",
        "    def __init__(self, state, parent=None):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.g = 0\n",
        "        self.h = 0\n",
        "        self.f = 0\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.f < other.f\n",
        "\n",
        "def get_successors(node, doc1_len, doc2_len):\n",
        "    moves = [(1, 1, 0), (0, 1, 1), (1, 0, 2)]\n",
        "    successors = []\n",
        "    for move in moves:\n",
        "        new_state = (node.state[0] + move[0], node.state[1] + move[1], move[2])\n",
        "        if new_state[0] <= doc1_len and new_state[1] <= doc2_len:\n",
        "            successors.append(Node(new_state, node))\n",
        "    return successors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YmGQi2f8wFzG"
      },
      "outputs": [],
      "source": [
        "# semantic distance calculation\n",
        "def semantic_distance(sent1, sent2):\n",
        "    words1 = set(sent1.split())\n",
        "    words2 = set(sent2.split())\n",
        "    common_words = words1.intersection(words2)\n",
        "    return 1 - len(common_words) / max(len(words1), len(words2))\n",
        "\n",
        "# heuristic function\n",
        "def heuristic(state, doc1, doc2):\n",
        "    remaining_sentences1 = len(doc1) - state[0]\n",
        "    remaining_sentences2 = len(doc2) - state[1]\n",
        "    return abs(remaining_sentences1 - remaining_sentences2)\n",
        "\n",
        "\n",
        "# A* star search\n",
        "def a_star_search(doc1, doc2):\n",
        "    start_state = (0, 0, 0)\n",
        "    goal_state = (len(doc1), len(doc2), 0)\n",
        "    start_node = Node(start_state)\n",
        "    open_list = [start_node]\n",
        "    closed_set = set()\n",
        "\n",
        "    while open_list:\n",
        "        current_node = heapq.heappop(open_list)\n",
        "\n",
        "        if current_node.state[:2] == goal_state[:2]:\n",
        "            path = []\n",
        "            while current_node:\n",
        "                path.append(current_node.state)\n",
        "                current_node = current_node.parent\n",
        "            return path[::-1]\n",
        "\n",
        "        closed_set.add(current_node.state)\n",
        "\n",
        "        for successor in get_successors(current_node, len(doc1), len(doc2)):\n",
        "            if successor.state in closed_set:\n",
        "                continue\n",
        "\n",
        "            successor.g = current_node.g + semantic_distance(\n",
        "                doc1[successor.state[0]-1] if successor.state[0] > 0 else \"\",\n",
        "                doc2[successor.state[1]-1] if successor.state[1] > 0 else \"\"\n",
        "            )\n",
        "            successor.h = heuristic(successor.state, doc1, doc2)\n",
        "            successor.f = successor.g + successor.h\n",
        "\n",
        "            heapq.heappush(open_list, successor)\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nxlPfjvcwF1Z"
      },
      "outputs": [],
      "source": [
        "# Plagiarism Detection with threshold 0.2\n",
        "def detect_plagiarism(doc1, doc2, threshold=0.2):\n",
        "    alignment = a_star_search(doc1, doc2)\n",
        "    plagiarism_detected = []\n",
        "\n",
        "    for i in range(1, len(alignment)):\n",
        "        prev, curr = alignment[i-1], alignment[i]\n",
        "        if curr[2] == 0:  # Sentences aligned\n",
        "            similarity = 1 - semantic_distance(doc1[curr[0]-1], doc2[curr[1]-1])\n",
        "            if similarity > threshold:\n",
        "                plagiarism_detected.append((curr[0]-1, curr[1]-1, similarity))\n",
        "\n",
        "    return plagiarism_detected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfGojGs6wF3s",
        "outputId": "a0bee9ca-4c5a-4179-8e65-5923e404ec21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plagiarism Detection Results:\n",
            "Document 1, Sentence 1: artificial intelligence is revolutionizing industries\n",
            "Document 2, Sentence 1: artificial intelligence is revolutionizing industries\n",
            "Similarity: 1.00\n",
            "\n",
            "Document 1, Sentence 2: machine learning algorithms can process vast amounts of data\n",
            "Document 2, Sentence 2: machine learning algorithms can process vast amounts of data\n",
            "Similarity: 1.00\n",
            "\n",
            "Document 1, Sentence 3: neural networks mimic the human brains structure\n",
            "Document 2, Sentence 3: neural networks mimic the human brains structure\n",
            "Similarity: 1.00\n",
            "\n",
            "Total sentences in Document 1: 3\n",
            "Total sentences in Document 2: 3\n",
            "Number of potentially plagiarized sentences: 3\n"
          ]
        }
      ],
      "source": [
        "# Preprocesssing \n",
        "doc1 = preprocess_text(read_file(\"/content/drive/MyDrive/Test/Test_1/doc1.txt\"))\n",
        "doc2 = preprocess_text(read_file(\"/content/drive/MyDrive/Test/Test_1/doc2.txt\"))\n",
        "\n",
        "# Plagiarism detection\n",
        "plagiarism_results = detect_plagiarism(doc1, doc2)\n",
        "\n",
        "# Getting the results (similarity)\n",
        "print(\"Plagiarism Detection Results:\")\n",
        "for i, j, similarity in plagiarism_results:\n",
        "  print(f\"Document 1, Sentence {i+1}: {doc1[i]}\")\n",
        "  print(f\"Document 2, Sentence {j+1}: {doc2[j]}\")\n",
        "  print(f\"Similarity: {similarity:.2f}\")\n",
        "  print()\n",
        "\n",
        "# Final result \n",
        "print(f\"Total sentences in Document 1: {len(doc1)}\")\n",
        "print(f\"Total sentences in Document 2: {len(doc2)}\")\n",
        "print(f\"Number of potentially plagiarized sentences: {len(plagiarism_results)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiNzA_WRzunR",
        "outputId": "84c2e01d-793a-479f-bff5-6c2a1991e135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plagiarism Detection Results:\n",
            "Document 1, Sentence 1: quantum computing leverages quantum physics concepts\n",
            "Document 2, Sentence 1: quantum computation utilizes quantum physics concepts\n",
            "Similarity: 0.60\n",
            "\n",
            "Document 1, Sentence 2: qubits can exist in multiple states simultaneously\n",
            "Document 2, Sentence 2: quantum bits can be in various states at once\n",
            "Similarity: 0.33\n",
            "\n",
            "Total sentences in Document 1: 3\n",
            "Total sentences in Document 2: 3\n",
            "Number of potentially plagiarized sentences: 2\n"
          ]
        }
      ],
      "source": [
        "# Preprocesssing \n",
        "doc1 = preprocess_text(read_file(\"/content/drive/MyDrive/Test/Test_2/doc1.txt\"))\n",
        "doc2 = preprocess_text(read_file(\"/content/drive/MyDrive/Test/Test_2/doc2.txt\"))\n",
        "\n",
        "# Plagiarism detection\n",
        "plagiarism_results = detect_plagiarism(doc1, doc2)\n",
        "\n",
        "# Getting the results (similarity)\n",
        "print(\"Plagiarism Detection Results:\")\n",
        "for i, j, similarity in plagiarism_results:\n",
        "  print(f\"Document 1, Sentence {i+1}: {doc1[i]}\")\n",
        "  print(f\"Document 2, Sentence {j+1}: {doc2[j]}\")\n",
        "  print(f\"Similarity: {similarity:.2f}\")\n",
        "  print()\n",
        "\n",
        "# Final result \n",
        "print(f\"Total sentences in Document 1: {len(doc1)}\")\n",
        "print(f\"Total sentences in Document 2: {len(doc2)}\")\n",
        "print(f\"Number of potentially plagiarized sentences: {len(plagiarism_results)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAagXQVWwF6O",
        "outputId": "f7d2ed1d-363a-4601-a0ad-f439a70b398d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plagiarism Detection Results:\n",
            "Total sentences in Document 1: 3\n",
            "Total sentences in Document 2: 3\n",
            "Number of potentially plagiarized sentences: 0\n"
          ]
        }
      ],
      "source": [
        "# Preprocesssing \n",
        "doc1 = preprocess_text(read_file(\"/content/drive/MyDrive/Test/Test_3/doc1.txt\"))\n",
        "doc2 = preprocess_text(read_file(\"/content/drive/MyDrive/Test/Test_3/doc2.txt\"))\n",
        "\n",
        "# Plagiarism detection\n",
        "plagiarism_results = detect_plagiarism(doc1, doc2)\n",
        "\n",
        "# Getting the results (similarity)\n",
        "print(\"Plagiarism Detection Results:\")\n",
        "for i, j, similarity in plagiarism_results:\n",
        "  print(f\"Document 1, Sentence {i+1}: {doc1[i]}\")\n",
        "  print(f\"Document 2, Sentence {j+1}: {doc2[j]}\")\n",
        "  print(f\"Similarity: {similarity:.2f}\")\n",
        "  print()\n",
        "\n",
        "# Final result \n",
        "print(f\"Total sentences in Document 1: {len(doc1)}\")\n",
        "print(f\"Total sentences in Document 2: {len(doc2)}\")\n",
        "print(f\"Number of potentially plagiarized sentences: {len(plagiarism_results)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OguKQ1MgwF8T",
        "outputId": "9d146993-bae0-4cd7-d02c-ff9964ff2e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plagiarism Detection Results:\n",
            "Document 1, Sentence 1: natural language processing nlp allows computers to understand human language\n",
            "Document 2, Sentence 1: natural language processing nlp allows computers to understand human language\n",
            "Similarity: 1.00\n",
            "\n",
            "Total sentences in Document 1: 3\n",
            "Total sentences in Document 2: 3\n",
            "Number of potentially plagiarized sentences: 1\n"
          ]
        }
      ],
      "source": [
        "# Preprocesssing \n",
        "doc1 = preprocess_text(read_file(\"/content/drive/MyDrive/Test/Test_4/doc1.txt\"))\n",
        "doc2 = preprocess_text(read_file(\"/content/drive/MyDrive/Test/Test_4/doc2.txt\"))\n",
        "\n",
        "# Plagiarism detection\n",
        "plagiarism_results = detect_plagiarism(doc1, doc2)\n",
        "\n",
        "# Getting the results (similarity)\n",
        "print(\"Plagiarism Detection Results:\")\n",
        "for i, j, similarity in plagiarism_results:\n",
        "  print(f\"Document 1, Sentence {i+1}: {doc1[i]}\")\n",
        "  print(f\"Document 2, Sentence {j+1}: {doc2[j]}\")\n",
        "  print(f\"Similarity: {similarity:.2f}\")\n",
        "  print()\n",
        "\n",
        "# Final result \n",
        "print(f\"Total sentences in Document 1: {len(doc1)}\")\n",
        "print(f\"Total sentences in Document 2: {len(doc2)}\")\n",
        "print(f\"Number of potentially plagiarized sentences: {len(plagiarism_results)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwT1rpp5wF_2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
